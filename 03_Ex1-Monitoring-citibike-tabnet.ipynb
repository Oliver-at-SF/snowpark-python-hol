{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Engineering Exercise 1:\n",
    "In this section of the demo, we will utilize Snowpark's Python client-side Dataframe API and server-side runtime to build an **ML ops monitoring process**.  For ML governance we need to monitor model performance over time. We will be building 100's of models (one per station) so as part of the pipeline we will add a step to evaluate model performance and save metrics for each training/inference run.\n",
    "\n",
    "Additionally, since the data science teams may use many different model frameworks, we want to have a standard evaluation framework instead of using the model's built-in evaluation which may different for each framework or version.  We will deploy the evaluation functions to the Snowpark Python server-side runtime as UDF so that all projects will have a **standard, centralized framework for evaluation and monitoring**.  We will save the model performance metrics in tables for historical analysis and drift detection as well as full reproducibility to support the company's GDPR policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Historical trips in the `TRIPS` table. Predictions in `PRED_<model_id>` table. Unique model ID number.  \n",
    "Output: Evaluation metrics in `EVAL_<model_id>` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q rexmex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate features for one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snp\n",
    "import json\n",
    "import getpass \n",
    "\n",
    "with open('creds.json') as f:\n",
    "    data = json.load(f)\n",
    "    connection_parameters = {\n",
    "      'account': data['account'],\n",
    "      'user': data['username'],\n",
    "      'password': data['password'], #getpass.getpass(),\n",
    "      'role': data['role'],\n",
    "      'schema': data['schema'],\n",
    "      'database': data['database'],\n",
    "      'warehouse': data['warehouse']}\n",
    "\n",
    "session = snp.Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "trips_table_name = 'TRIPS'\n",
    "holiday_table_name = 'HOLIDAYS'\n",
    "precip_table_name = 'WEATHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "model_id = str(uuid.uuid1()).replace('-', '_')\n",
    "\n",
    "feature_view_name = 'TRIPS_FEATURES_<station_id>_'+str(model_id)\n",
    "pred_table_name = 'PRED_'+str(model_id)\n",
    "eval_table_name = 'EVAL_'+str(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import functions as F\n",
    "from citibike_ml.feature_engineering import generate_features\n",
    "\n",
    "station_id = '519'\n",
    "\n",
    "input_df = session.table(trips_table_name).filter(F.col('START_STATION_ID') == station_id)\n",
    "feature_df = generate_features(session=session, \n",
    "                               input_df=input_df, \n",
    "                               holiday_table_name=holiday_table_name, \n",
    "                               precip_table_name=precip_table_name)\n",
    "\n",
    "feature_df.sort('DATE').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model for these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, cutpoint=365, cat_idxs=[]):    \n",
    "    X_valid = X[-cutpoint:]\n",
    "    y_valid = y[-cutpoint:]\n",
    "    X_train = X[:-cutpoint]\n",
    "    y_train = y[:-cutpoint]\n",
    "\n",
    "    from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "    max_epochs = 1000\n",
    "    regression_model = TabNetRegressor(cat_idxs=cat_idxs)\n",
    "\n",
    "    regression_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        max_epochs=max_epochs,\n",
    "        patience=100,\n",
    "        batch_size=1024, \n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False)\n",
    "    \n",
    "    return regression_model\n",
    "\n",
    "def predict(model, X):\n",
    "    y_hat = model.predict(X).reshape(-1)\n",
    "    return y_hat\n",
    "    \n",
    "def plot(df, x_lab:str, y_true_lab:str, y_pred_lab:str):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    df = pd.melt(df, id_vars=[x_lab], value_vars=[y_true_lab, y_pred_lab])\n",
    "    ax = sns.lineplot(x=x_lab, y='value', hue='variable', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "target = ['COUNT']\n",
    "feature_columns = [feature.replace('\\\"', '') for feature in feature_df.columns]\n",
    "feature_columns.remove(target[0])\n",
    "feature_columns.remove('DATE')\n",
    "feature_columns.remove('STATION_ID')\n",
    "\n",
    "df = feature_df.sort('DATE', ascending=True).toPandas()\n",
    "\n",
    "model = train(df[feature_columns].values, df[target].values)\n",
    "df['PRED'] = predict(model, df[feature_columns].values).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluation: \n",
    "We will use [rexmex](https://rexmex.readthedocs.io/en/latest/index.html) for consistent evaluation rather than the models' built-in eval metrics.  Evaluation metrics will be saved as table output tagged with the model_id.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rexmex import RatingMetricSet, ScoreCard\n",
    "\n",
    "metric_set = RatingMetricSet()\n",
    "score_card = ScoreCard(metric_set)\n",
    "\n",
    "input_column_names = ['COUNT', 'PRED', 'STATION_ID']\n",
    "eval_df = df[input_column_names].rename(columns={'COUNT': 'y_true', 'PRED':'y_score'})\n",
    "\n",
    "eval_df = score_card.generate_report(eval_df,grouping=['STATION_ID']).reset_index()\n",
    "eval_df.drop('level_1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deploy Evaluation UDF\n",
    "We will create a UDF for the evaluation with Rexmex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_output_func(input_data: list, \n",
    "                           y_true_name: str, \n",
    "                           y_score_name: str,\n",
    "                           group_id_name: str) -> str:\n",
    "    import pandas as pd\n",
    "    from rexmex import RatingMetricSet, ScoreCard\n",
    "    \n",
    "    metric_set = RatingMetricSet()\n",
    "    score_card = ScoreCard(metric_set)\n",
    "    \n",
    "    input_column_names = [y_true_name, y_score_name, group_id_name]\n",
    "    df = pd.DataFrame(input_data, columns = input_column_names)\n",
    "    df.rename(columns={y_true_name: 'y_true', y_score_name:'y_score'}, inplace=True)\n",
    "    \n",
    "    df = score_card.generate_report(df,grouping=[group_id_name]).reset_index()\n",
    "    df.drop('level_1', axis=1, inplace=True)\n",
    "    \n",
    "    return [df.values.tolist(), df.columns.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying the UDF to Snowflake makes it available for all users.  This is a regression evaluation.  Likely we will want to deploy a categorical function as well or add if/then logic to our single instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from citibike_ml.model_eval import eval_model_output_func\n",
    "\n",
    "session.clearImports()\n",
    "session.addImport('./include/rexmex.zip')\n",
    "session.addImport('citibike_ml')\n",
    "\n",
    "model_stage_name = 'model_stage'\n",
    "_ = session.sql('CREATE STAGE IF NOT EXISTS model_stage').collect()\n",
    "\n",
    "eval_model_output_udf = session.udf.register(eval_model_output_func, \n",
    "                                              name=\"eval_model_output_udf\",\n",
    "                                              is_permanent=True,\n",
    "                                              stage_location='@'+str(model_stage_name), \n",
    "                                              replace=True)\n",
    "\n",
    "eval_model_output_udf.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the output of the model eval UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citibike_ml.mlops_pipeline import generate_feature_views, train_predict_feature_views, deploy_pred_train_udf\n",
    "\n",
    "station_train_pred_udf_name = deploy_pred_train_udf(session=session,\n",
    "                                                    function_name='station_train_predict_udf', \n",
    "                                                    model_stage_name='model_stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view_names = generate_feature_views(session=session, \n",
    "                                            clone_table_name=trips_table_name, \n",
    "                                            feature_view_name=feature_view_name,\n",
    "                                            holiday_table_name=holiday_table_name,\n",
    "                                            precip_table_name=precip_table_name,\n",
    "                                            target_column='COUNT',\n",
    "                                            top_n=2)\n",
    "\n",
    "pred_table_name = train_predict_feature_views(session=session, \n",
    "                                              station_train_pred_udf_name=station_train_pred_udf_name,\n",
    "                                              feature_view_names=feature_view_names, \n",
    "                                              pred_table_name=pred_table_name)\n",
    "\n",
    "pred_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "eval_df = session.table(pred_table_name)\\\n",
    "                 .select(F.array_agg(F.array_construct('COUNT', 'PRED', 'STATION_ID')).alias('INPUT_DATA'))\n",
    "\n",
    "output_df = eval_df.select(F.call_udf('eval_model_output_udf',\n",
    "                                      'INPUT_DATA',\n",
    "                                      F.lit('COUNT'), \n",
    "                                      F.lit('PRED'),\n",
    "                                      F.lit('STATION_ID')).alias('OUTPUT_DATA')).collect()\n",
    "\n",
    "df = pd.DataFrame(data = ast.literal_eval(output_df[0][0])[0], \n",
    "                      columns = ast.literal_eval(output_df[0][0])[1])\n",
    "\n",
    "eval_df = session.createDataFrame(df).write.mode('overwrite').saveAsTable(eval_table_name)\n",
    "\n",
    "df = session.table(eval_table_name).toPandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate all functions for orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile citibike_ml/model_eval.py\n",
    "\n",
    "def eval_model_output_func(input_data: list, \n",
    "                           y_true_name: str, \n",
    "                           y_score_name: str,\n",
    "                           group_id_name: str) -> str:\n",
    "    import pandas as pd\n",
    "    from rexmex import RatingMetricSet, ScoreCard\n",
    "    \n",
    "    metric_set = RatingMetricSet()\n",
    "    score_card = ScoreCard(metric_set)\n",
    "    \n",
    "    input_column_names = [y_true_name, y_score_name, group_id_name]\n",
    "    df = pd.DataFrame(input_data, columns = input_column_names)\n",
    "    df.rename(columns={y_true_name: 'y_true', y_score_name:'y_score'}, inplace=True)\n",
    "    \n",
    "    df = score_card.generate_report(df,grouping=[group_id_name]).reset_index()\n",
    "    df.drop('level_1', axis=1, inplace=True)\n",
    "    \n",
    "    return [df.values.tolist(), df.columns.tolist()]\n",
    "\n",
    "def deploy_eval_udf(session, function_name, model_stage_name) -> str:\n",
    "    from citibike_ml.model_eval import eval_model_output_func\n",
    "\n",
    "    session.clearImports()\n",
    "    session.addImport('./include/rexmex.zip')\n",
    "    session.addImport('citibike_ml')\n",
    "\n",
    "    eval_model_output_udf = session.udf.register(eval_model_output_func, \n",
    "                                                  name=function_name,\n",
    "                                                  is_permanent=True,\n",
    "                                                  stage_location='@'+str(model_stage_name), \n",
    "                                                  replace=True)\n",
    "\n",
    "    return eval_model_output_udf.name\n",
    "\n",
    "def evaluate_station_predictions(session, pred_table_name, eval_model_udf_name, eval_table_name) -> str:\n",
    "    from snowflake.snowpark import functions as F\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "    \n",
    "    eval_df = session.table(pred_table_name)\\\n",
    "                     .select(F.array_agg(F.array_construct('COUNT', 'PRED', 'STATION_ID')).alias('input_data'))\n",
    "\n",
    "    output_df = eval_df.select(F.call_udf(eval_model_udf_name,\n",
    "                                          'INPUT_DATA',\n",
    "                                          F.lit('COUNT'), \n",
    "                                          F.lit('PRED'),\n",
    "                                          F.lit('STATION_ID'))).collect()\n",
    "    \n",
    "    df = pd.DataFrame(data = ast.literal_eval(output_df[0][0])[0], \n",
    "                      columns = ast.literal_eval(output_df[0][0])[1])\n",
    "\n",
    "    eval_df = session.createDataFrame(df).write.saveAsTable(eval_table_name)\n",
    "\n",
    "\n",
    "    return eval_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "cforbe"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "msauthor": "trbye"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
