{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3bec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip -q install \"apache-airflow[celery]==2.2.3\" --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.2.3/constraints-no-providers-3.8.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54820ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datetime import datetime, timedelta\n",
    "#from webbrowser import get\n",
    "#from xml.etree.ElementInclude import include\n",
    "#import uuid\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5)\n",
    "}\n",
    "\n",
    "files_to_download = ['202003-citibike-tripdata.csv.zip']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33fa897",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile snowpark_connection.py\n",
    "\n",
    "def snowpark_connect():\n",
    "    import os, json \n",
    "    import snowflake.snowpark as snp\n",
    "\n",
    "#     local_airflow_path = '/usr/local/airflow/'\n",
    "#     with open(os.path.join(local_airflow_path, 'include', 'creds.json')) as f:    \n",
    "    with open(os.path.join('creds.json')) as f:\n",
    "        data = json.load(f)\n",
    "        connection_parameters = {\n",
    "        'account': data['account'],\n",
    "        'user': data['username'],\n",
    "        'password': data['password'],\n",
    "        'role': data['role'],\n",
    "        'warehouse': data['warehouse'],\n",
    "        'database': data['database'],\n",
    "        'schema': data['schema']}\n",
    "        session = snp.Session.builder.configs(connection_parameters).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d98d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(default_args=default_args, schedule_interval=None, start_date=datetime(2022, 1, 24), catchup=False, tags=['test'])\n",
    "def snowpark_citibike_ml_taskflow(files_to_download:list):\n",
    "    \"\"\"\n",
    "    End to end Astronomer / Snowflake ML Demo\n",
    "    \"\"\"\n",
    "\n",
    "    import uuid\n",
    "    \n",
    "    state_dict = {\n",
    "    \"download_base_url\":\"https://s3.amazonaws.com/tripdata/\",\n",
    "    \"load_table_name\":\"RAW_\",\n",
    "    \"trips_table_name\":\"TRIPS\",\n",
    "    \"load_stage_name\":\"LOAD_STAGE\",\n",
    "    \"model_stage_name\":\"MODEL_STAGE\",\n",
    "    \"model_id\": str(uuid.uuid1()).replace('-', '_')\n",
    "    }\n",
    "    \n",
    "    @task()\n",
    "    def snowpark_database_setup(state_dict:dict)-> dict: \n",
    "        from snowpark_connection import snowpark_connect\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "\n",
    "        start_date, end_date = session.table(state_dict['trips_table_name']) \\\n",
    "                              .select(F.min('STARTTIME'), F.max('STARTTIME')).collect()[0][0:2]\n",
    "        state_dict.update({\"start_date\":start_date})\n",
    "        state_dict.update({\"end_date\":end_date})\n",
    "        \n",
    "        _ = session.sql('CREATE STAGE IF NOT EXISTS ' + str(model_stage_name)).collect()\n",
    "        _ = session.sql('CREATE STAGE IF NOT EXISTS ' + str(load_stage_name)).collect()\n",
    "        \n",
    "        session.close()\n",
    "\n",
    "        return state_dict\n",
    "    \n",
    "    @task()\n",
    "    def  incremental_elt_task(state_dict: dict, files_to_download:list)-> dict:\n",
    "        from ingest import incremental_elt\n",
    "        session = snowpark_connect()\n",
    "        \n",
    "        _ = incremental_elt(session=session, \n",
    "                            load_stage_name=state_dict['load_stage_name'], \n",
    "                            files_to_download=files_to_download, \n",
    "                            download_base_url=state_dict['download_base_url'], \n",
    "                            load_table_name=state_dict['load_table_name'], \n",
    "                            trips_table_name=state_dict['trips_table_name']\n",
    "                            )\n",
    "        \n",
    "        session.close()\n",
    "        return state_dict\n",
    "    \n",
    "    @task()\n",
    "    def deploy_model_udf_task(state_dict:dict)-> dict:\n",
    "        from mlops_pipeline import deploy_pred_train_udf\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "        model_udf_name = deploy_pred_train_udf(session=session, \n",
    "                                               function_name='station_train_predict_func', \n",
    "                                               model_stage_name=state_dict['model_stage_name']\n",
    "                                              )\n",
    "                \n",
    "        state_dict.update({\"model_udf_name\":model_udf_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "\n",
    "    @task()\n",
    "    def materialize_holiday_task(state_dict: dict)-> dict:\n",
    "        from mlops_pipeline import materialize_holiday_table\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "        \n",
    "        holiday_table_name = materialize_holiday_table(session=session,\n",
    "                                                       trips_table_name=state_dict['trips_table_name'], \n",
    "                                                       holiday_table_name='holidays'\n",
    "                                                      )\n",
    "        \n",
    "        state_dict.update({\"holiday_table_name\":holiday_table_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "\n",
    "    @task()\n",
    "    def materialize_precip_task(state_dict: dict)-> dict:\n",
    "        from mlops_pipeline import materialize_precip_table\n",
    "\n",
    "        session = snowpark_connect()\n",
    "        \n",
    "        precip_table_name = materialize_precip_table(session=session,\n",
    "                                                     trips_table_name=state_dict['trips_table_name'], \n",
    "                                                     precip_table_name='weather'\n",
    "                                                    )\n",
    "        \n",
    "        state_dict.update({\"precip_table_name\":precip_table_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "\n",
    "    @task()\n",
    "    def generate_feature_table_task(state_dict:dict, top_n:int)-> dict: \n",
    "        from mlops_pipeline import generate_feature_table\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "        \n",
    "        clone_table_name = 'TRIPS_CLONE_'+state_dict[\"model_id\"]\n",
    "        state_dict.update({\"clone_table_name\":clone_table_name})\n",
    "        \n",
    "        _ = session.sql('CREATE OR REPLACE TABLE '+clone_table_name+\" CLONE \"+state_dict[\"trips_table_name\"]).collect()\n",
    "        _ = session.sql('CREATE TAG IF NOT EXISTS model_id_tag').collect()\n",
    "        _ = session.sql(\"ALTER TABLE \"+clone_table_name+\" SET TAG model_id_tag = '\"+state_dict[\"model_id\"]+\"'\").collect()\n",
    "        \n",
    "        feature_table_name = generate_feature_table(session=session, \n",
    "                                                    clone_table_name=state_dict[\"clone_table_name\"], \n",
    "                                                    feature_table_name='TRIPS_FEATURES_'+state_dict[\"model_id\"], \n",
    "                                                    holiday_table_name=state_dict[\"holiday_table_name\"],\n",
    "                                                    precip_table_name=state_dict[\"precip_table_name\"],\n",
    "                                                    target_column='COUNT', \n",
    "                                                    top_n=top_n\n",
    "                                                   )\n",
    "        state_dict.update({\"feature_table_name\":feature_table_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "    \n",
    "    @task()\n",
    "    def bulk_train_predict_task(state_dict:dict)-> dict: \n",
    "        from mlops_pipeline import train_predict_feature_table\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "        pred_table_name = train_predict_feature_table(session=session, \n",
    "                                                      station_train_pred_udf_name=state_dict[\"model_udf_name\"], \n",
    "                                                      feature_table_name=state_dict[\"feature_table_name\"], \n",
    "                                                      pred_table_name='PRED_'+state_dict[\"model_id\"]\n",
    "                                                     )\n",
    "        \n",
    "        state_dict.update({\"pred_table_name\":pred_table_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "    \n",
    "    def deploy_eval_udf_task(state_dict:dict)-> dict:\n",
    "        from model_eval import deploy_eval_udf\n",
    "        \n",
    "        session = snowpark_connect()\n",
    "        eval_model_udf_name = deploy_eval_udf(session=session, \n",
    "                                              function_name='eval_model_output_func', \n",
    "                                              model_stage_name=state_dict['model_stage_name']\n",
    "                                              )\n",
    "                \n",
    "        state_dict.update({\"eval_model_udf_name\":eval_model_udf_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict\n",
    "\n",
    "    @task()\n",
    "    def eval_station_preds_task(state_dict:dict)-> dict:\n",
    "        from model_eval import evaluate_station_predictions\n",
    "\n",
    "        session = snowpark_connect()\n",
    "        eval_table_name = evaluate_station_predictions(session=session, \n",
    "                                                       pred_table_name=state_dict['pred_table_name'],\n",
    "                                                       eval_model_udf_name=state_dict['eval_model_udf_name'],\n",
    "                                                       eval_table_name='EVAL_'+state_dict[\"model_id\"]\n",
    "                                                       )\n",
    "        state_dict.update({\"eval_table_name\":eval_table_name})\n",
    "\n",
    "        session.close()\n",
    "        return state_dict                                               \n",
    "    \n",
    "    #Task order\n",
    "    state_dict = snowpark_database_setup(state_dict)\n",
    "    state_dict = incremental_elt_task(state_dict, files_to_download)\n",
    "    state_dict = deploy_model_udf_task(state_dict)\n",
    "    state_dict = materialize_holiday_task(state_dict)\n",
    "    state_dict = materialize_precip_task(state_dict)\n",
    "    state_dict = generate_feature_table_task(state_dict, top_n) \n",
    "    state_dict = bulk_train_predict_task(state_dict)\n",
    "    state_dict = deploy_eval_udf_task(state_dict)\n",
    "    state_dict = eval_station_preds_task(state_dict)        \n",
    "    \n",
    "    return state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df230d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
